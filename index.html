<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Real-Time Rendering of ZipNeRF Model</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            background-color: #f4f4f4;
            color: #333;
            text-align: center;
            padding: 50px;
        }
        h1 {
            font-size: 24px;
            margin-bottom: 20px;
        }
        h2 {
            font-size: 20px;
            margin-top: 30px;
        }
        p, ul {
            font-size: 16px;
            text-align: left;
            margin: 0 auto 20px;
            max-width: 800px;
        }
        ul {
            list-style-type: disc;
            padding-left: 40px;
        }
        blockquote {
            font-size: 16px;
            text-align: left;
            margin: 0 auto 20px;
            max-width: 800px;
            background-color: #eaeaea;
            padding: 10px 20px;
            border-left: 5px solid #ccc;
        }
        .container {
            display: flex;
            justify-content: center;
            gap: 50px;
            margin-top: 30px;
        }
        .option {
            text-align: center;
        }
        .option .icon {
            font-size: 64px;
            cursor: pointer;
            display: block;
            margin-bottom: 10px;
        }
        .option a {
            display: block;
            font-size: 18px;
            color: #007bff;
            text-decoration: none;
        }
        .option a:hover {
            text-decoration: underline;
        }
    </style>
</head>
<body>
    <h1>Real-Time Rendering of ZipNeRF Model</h1>
    <p>This website showcases the real-time rendering of a ZipNeRF model trained on imagery captured from my living room. Achieving real-time performance was possible through teacher distillation and baking techniques, as in SMERF. The images were taken using a standard iPhone camera.</p>

    <h2>Please choose among the following quality presets for visualization:</h2>
    <div class="container">
        <div class="option">
            <a href="https://p01onk7kh5l6ye-8003.proxy.runpod.net/?useDistanceGrid=true&useBits=true&dir=converted_perspective_room/sm_000&vfovy=70&exposure=0.016&near=0.02&quality=phone&mouseMode=map&submodelCacheSize=0">
                <span class="icon">&#128241;</span>
                <span>iPhone</span>
            </a>
        </div>
        <div class="option">
            <a href="https://p01onk7kh5l6ye-8003.proxy.runpod.net/?useDistanceGrid=true&useBits=true&dir=converted_perspective_room/sm_000&converted_perspective_room&mouseMode=fps&vfovy=70&exposure=0.016&near=0.02&quality=medium&mouseMode=fps">
                <span class="icon">&#128187;</span>
                <span>Laptop with weak GPU</span>
            </a>
        </div>
        <div class="option">
            <a href="https://p01onk7kh5l6ye-8003.proxy.runpod.net/?useDistanceGrid=true&useBits=true&dir=converted_perspective_room/sm_000&converted_perspective_room&mouseMode=fps&vfovy=70&exposure=0.016&near=0.02&quality=high&mouseMode=fps">
                <span class="icon">&#128187;</span>
                <span>Laptop with strong GPU <br> Macbook Air is fine! </span>
            </a>
        </div>
    </div>

    <h2>Tips for Producing Good Imagery with an iPhone Camera</h2>
    <ul>
        <li>Use fisheye mode or wide-angle mode. The iPhone's automatic undistortion setting removes radial distortion, making it suitable for perspective imagery.</li>
        <li>Lock the white balance to maintain consistent colors across images.</li>
        <li>Lock the exposure to reduce complexity in the scene, aiding feature mapping later.</li>
        <li>Ensure approximately 70% overlap between images.</li>
    </ul>
    <p>In my example, I recorded a video using the above settings, scanned each frame for the least blur, and selected frames on average every 0.5 seconds.</p>

    <h2>Image Processing to Obtain Poses</h2>
    <p><strong>Note:</strong> Using a GPU for these steps is highly recommended. If you took wide-angle images with an iPhone, distortion is already removed, so specify 'OPEN_CV' as perspective camera mode</p>
    <blockquote>
        <code>colmap feature_extractor</code><br>
        <code>colmap exhaustive_matcher</code><br>
        <code>colmap vocab_tree_matcher</code><br>
        <code>colmap mapper</code>
    </blockquote>
    <p>There is a recent, potentially better alternative to <code>colmap mapper</code>: <a href="https://github.com/colmap/glomap">GloMAP</a>.</p>

    <h2>Model Training Details</h2>
    <p>The teacher model was trained to full convergence, while the student model was not fully converged. For mesh extraction from the trained teacher model, visit the following repository: <a href="https://github.com/SuLvXiangXin/zipnerf-pytorch">zipnerf-pytorch</a>.</p>
</body>
</html>
